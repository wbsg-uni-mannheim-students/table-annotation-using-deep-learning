{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daabc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define which GPU to use\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8109a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, RobertaForSequenceClassification, RobertaConfig,RobertaTokenizer \n",
    "from util import parse_tagname, f1_score_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e327f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import (\n",
    "    collate_fn,\n",
    "    #CTA\n",
    "    CTASingleColumnDataset,\n",
    "    CTAAllTableDataset,\n",
    "    #CPA\n",
    "    CPASingleColumnDataset,\n",
    "    CPAAllTableDataset,\n",
    ")\n",
    "from model import BertForMultiOutputClassification, BertMultiPairPooler\n",
    "from util import f1_score_multilabel, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fe4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ecb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the task to evaluate\n",
    "#Possible method: cta, cpa or doduo(multi-task)\n",
    "method = 'doduo'\n",
    "#Specify which serialization strategy to use\n",
    "#Possible: single-column, all-table ... (+ new ones)\n",
    "serialization = 'all-table'\n",
    "#Specify which language model to use:\n",
    "#bert-base-uncased, roberta-base ...\n",
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f4d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'cta':\n",
    "    tasks = ['cta']\n",
    "elif method == 'cpa':\n",
    "    tasks = ['cpa']\n",
    "else:\n",
    "    tasks = ['cta', 'cpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0284de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "max_length = 32\n",
    "batch_size = 16\n",
    "#Number of classes per task\n",
    "task_num_class_dict = {\n",
    "        \"cta\": 91,\n",
    "        \"cpa\": 176\n",
    "    }\n",
    "filepaths_task_dict = {\n",
    "    \"cta\": \"data/CTA/cta_lm.pkl\",\n",
    "    \"cpa\": \"data/CPA/cpa_lm.pkl\",\n",
    "}\n",
    "serialization_method_dict = {\n",
    "    \"cta\": {\n",
    "        \"single-column\": CTASingleColumnDataset,\n",
    "        \"all-table\": CTAAllTableDataset\n",
    "    },\n",
    "    \"cpa\": {\n",
    "        \"single-column\": CPASingleColumnDataset,\n",
    "        \"all-table\": CPAAllTableDataset\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "250e6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer based on language model\n",
    "if 'roberta' in model_name:\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    base_model = 'roberta'\n",
    "else:\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    base_model = 'bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c9a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/doduo_cta_all-table_bert-base-uncased-bs16-ml-32.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiOutputClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultiOutputClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiOutputClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiOutputClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading already processed test dataset\n",
      "test_macro_f1=0.8433 test_micro_f1=0.8538 \n",
      "model/doduo_cpa_all-table_bert-base-uncased-bs16-ml-32.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiOutputClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultiOutputClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiOutputClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiOutputClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use column-pair pooling\n",
      "Loading already processed test dataset\n",
      "test_macro_f1=0.7758 test_micro_f1=0.8037 \n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    \n",
    "    if not os.path.exists('eval/'):\n",
    "        print(\"{} not exist. Created.\".format('eval/'))\n",
    "        os.makedirs('eval/')\n",
    "        \n",
    "    model_path = \"model/{}_{}_{}_{}-bs{}-ml-{}.pt\".format(method, task, serialization, model_name, batch_size, max_length)\n",
    "    print(model_path)\n",
    "    \n",
    "    if serialization == 'single-column':\n",
    "        #Choose model\n",
    "        if 'roberta' in model_name:\n",
    "            model_config = RobertaConfig.from_pretrained(model_name, num_labels=task_num_class_dict[task])\n",
    "            model = RobertaForSequenceClassification(model_config).to(device)\n",
    "        else:\n",
    "            model_config = BertConfig.from_pretrained(model_name, num_labels=task_num_class_dict[task])\n",
    "            model = BertForSequenceClassification(model_config).to(device)\n",
    "        \n",
    "        #Choose serialization\n",
    "        dataset_serialization = serialization_method_dict[task][serialization]\n",
    "        \n",
    "    #Add more conditions when adding new serialization methods        \n",
    "    else:\n",
    "        if 'roberta' in model_name:\n",
    "            model = RobertaForMultiOutputClassification.from_pretrained(\n",
    "                    model_name,\n",
    "                    num_labels=task_num_class_dict[task],\n",
    "                    output_attentions=False,\n",
    "                    output_hidden_states=False,\n",
    "                ).to(device)\n",
    "        else:\n",
    "            model = BertForMultiOutputClassification.from_pretrained(\n",
    "                    model_name,\n",
    "                    num_labels=task_num_class_dict[task],\n",
    "                    output_attentions=False,\n",
    "                    output_hidden_states=False,\n",
    "                ).to(device)\n",
    "        \n",
    "        dataset_serialization = serialization_method_dict[task][serialization]\n",
    "            \n",
    "        #What is the difference: using multipair pooler instead of usual pooler\n",
    "        if task == \"cpa\":\n",
    "            print(\"Use column-pair pooling\")\n",
    "            #Change for Roberta!!!\n",
    "            # Use column pair embeddings\n",
    "            config = BertConfig.from_pretrained(model_name)\n",
    "            model.bert.pooler = BertMultiPairPooler(config).to(device)\n",
    "            \n",
    "            \n",
    "    #Load test datasets and datasetloaders\n",
    "    test_dataset = dataset_serialization(filepath=filepaths_task_dict[task],\n",
    "                                   split=\"test\",\n",
    "                                   tokenizer=tokenizer,\n",
    "                                   max_length=max_length,\n",
    "                                   bert=base_model,\n",
    "                                   device=device)\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 collate_fn=collate_fn)\n",
    "    \n",
    "\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "    \n",
    "    eval_dict = {}\n",
    "    for batch_idx, batch in enumerate(test_dataloader):\n",
    "        if serialization == 'single-column':\n",
    "            \n",
    "            batch_input_ids = batch[\"data\"].T.to(device)\n",
    "            batch_mask = batch[\"attention\"].T.to(device)\n",
    "            #For cross-entropy loss labels should not be vectors\n",
    "            batch_labels = torch.tensor([label.tolist().index(1) for label in batch[\"label\"]]).to(device)\n",
    "\n",
    "            loss, logits = model(batch_input_ids, token_type_ids=None, attention_mask=batch_mask, labels=batch_labels, return_dict=False)\n",
    "\n",
    "            for p in logits.argmax(axis=-1):\n",
    "                y = [0] * logits.shape[1]\n",
    "                y[p] = 1\n",
    "                test_predictions.append(y)\n",
    "\n",
    "            test_labels += batch[\"label\"].cpu().detach().numpy().tolist()\n",
    "        else:\n",
    "            logits, = model(input_ids = batch[\"data\"].T)\n",
    "\n",
    "            # Align the tensor shape when the size is 1\n",
    "            if len(logits.shape) == 2:\n",
    "                logits = logits.unsqueeze(0)\n",
    "\n",
    "            cls_indexes = torch.nonzero( batch[\"data\"].T == tokenizer.cls_token_id)\n",
    "            filtered_logits = torch.zeros(cls_indexes.shape[0], logits.shape[2]).to(device)\n",
    "\n",
    "            #Mark where CLS tokens are located\n",
    "            for n in range(cls_indexes.shape[0]):\n",
    "                i, j = cls_indexes[n]\n",
    "                logit_n = logits[i, j, :]\n",
    "                filtered_logits[n] = logit_n\n",
    "\n",
    "            if task == 'cta':\n",
    "                for pred in filtered_logits.argmax(axis=-1):\n",
    "                    y = [0] * filtered_logits.shape[1]\n",
    "                    y[pred] = 1\n",
    "                    test_predictions.append(y)\n",
    "\n",
    "                test_labels += batch[\"label\"].cpu().detach().numpy().tolist()\n",
    "                \n",
    "            else:\n",
    "                all_preds = []\n",
    "                for pred in filtered_logits.argmax(axis=-1):\n",
    "                    y = [0] * filtered_logits.shape[1]\n",
    "                    y[pred] = 1\n",
    "                    all_preds.append(y)\n",
    "                    \n",
    "                all_labels = batch[\"label\"].cpu().detach().numpy()\n",
    "                # Ignore the very first CLS token\n",
    "                idxes = np.where(all_labels > 0)[0]\n",
    "                test_predictions += [ pred for i, pred in enumerate(all_preds) if i in idxes ]\n",
    "                test_labels += [label.tolist() for label in batch[\"label\"] if 1 in label.tolist()]\n",
    "                \n",
    "    \n",
    "    ts_micro_f1, ts_macro_f1, ts_class_f1, ts_conf_mat = f1_score_multilabel(test_labels, test_predictions)\n",
    "    \n",
    "    eval_dict[\"ts_micro_f1\"] = ts_micro_f1\n",
    "    if type(ts_class_f1) != list:\n",
    "        ts_class_f1 = ts_class_f1.tolist()\n",
    "    eval_dict[\"ts_class_f1\"] = ts_class_f1\n",
    "    if type(ts_conf_mat) != list:\n",
    "        ts_conf_mat = ts_conf_mat.tolist()\n",
    "    eval_dict[\"confusion_matrix\"] = ts_conf_mat\n",
    "    \n",
    "    print(\"test_macro_f1={:.4f} test_micro_f1={:.4f} \"\n",
    "        .format(ts_macro_f1, ts_micro_f1))\n",
    "        \n",
    "#     with open(output_filepath, \"w\") as fout:\n",
    "#         json.dump(eval_dict, fout)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f909766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf99447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17048f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
